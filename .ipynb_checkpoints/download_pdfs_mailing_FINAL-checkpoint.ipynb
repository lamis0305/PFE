{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32346047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Recherche des PDFs: Rapports FTUSA sur les indicateurs de marché\n",
      "URL: https://www.ftusanet.org/indicateurs-du-marche-2/\n",
      "\n",
      "Analyse spécifique du site FTUSA : https://www.ftusanet.org/indicateurs-du-marche-2/\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2023.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2022.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2022.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2021.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2020.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Tentative 1/1\n",
      "  Le fichier Rapport-FTUSA-2012.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "--------------------------------------------------\n",
      "Recherche des PDFs: Rapports annuels du CGA\n",
      "URL: https://www.cga.gov.tn/index.php?id=96&L=0\n",
      "\n",
      "Analyse du site : https://www.cga.gov.tn/index.php?id=96&L=0\n",
      "\n",
      "Tentative 1/3\n",
      "  Le fichier appel_d_offre_num_02-2022.pdf existe déjà. Téléchargement ignoré.\n",
      "  Nouvelle tentative dans 5 secondes...\n",
      "\n",
      "Tentative 2/3\n",
      "  Le fichier appel_d_offre_num_02-2022.pdf existe déjà. Téléchargement ignoré.\n",
      "  Nouvelle tentative dans 5 secondes...\n",
      "\n",
      "Tentative 3/3\n",
      "  Le fichier appel_d_offre_num_02-2022.pdf existe déjà. Téléchargement ignoré.\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/RAP_CGA_FR_ANG_2022.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2022\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/RAP_CGA_FR_ANG_2021_nouvelle_version.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2021\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/RAPPORT_CGA_FR_ANG_2020.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2020\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR-ANG_-_CGA_2019_-_VF.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2019\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_CGA_FR-ANG_-_2018_final.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2018\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/rapport_FR___ANG_2017.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2017\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/CGA_RAPPORT_FR_-ANG_2016.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2016\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/CGA_RAPPORT_FR-ANG2015.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/CGA_RAPPORT_FR-ANG2015.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2015\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/CGA_RAP_FR_ANG_2014.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/CGA_RAP_FR_ANG_2014.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2014\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/rapport_annuel__FR_2013.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/rapport_annuel__FR_2013.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2013\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2012.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2012.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2012\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2011.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2011.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2011\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2010.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2010.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2010\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2008.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2008.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2008\n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2006.pdf\n",
      "  Titre: \n",
      "\n",
      "Fichier sans date détecté - vérification manuelle recommandée:\n",
      "  URL: https://www.cga.gov.tn/fileadmin/contenus/pdf/Rapport_FR_2006.pdf\n",
      "  Titre: rapport annuel du secteur des assurances 2006\n",
      "\n",
      "Opération terminée. 0 nouveaux fichiers téléchargés avec succès.\n",
      "\n",
      "Aucun nouveau rapport - aucun email envoyé\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, unquote\n",
    "\n",
    "# Configuration\n",
    "DOWNLOAD_DIR = \"scraped_pdfs_final_3\"\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB\n",
    "DOWNLOAD_LOG = os.path.join(DOWNLOAD_DIR, \"download_log.txt\")\n",
    "MAX_RETRIES = 3\n",
    "INITIAL_TIMEOUT = 30  # seconds\n",
    "BACKOFF_FACTOR = 2  # Multiply timeout by this factor on each retry\n",
    "CHUNK_SIZE = 8192  # bytes\n",
    "\n",
    "EMAIL_CONFIG = {\n",
    "    'sender': 'reports.new.alerts@gmail.com',\n",
    "    'password': 'cerp jauo kveh epip',\n",
    "    'recipient': 'lamis.mokrani@esprit.tn',\n",
    "    'smtp_server': 'smtp.gmail.com',\n",
    "    'smtp_port': 587\n",
    "}\n",
    "\n",
    "def send_email_notification(new_reports):\n",
    "    try:\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = EMAIL_CONFIG['sender']\n",
    "        msg['To'] = EMAIL_CONFIG['recipient']\n",
    "        msg['Subject'] = f\"Nouveaux rapports disponibles ({len(new_reports)} nouveaux)\"\n",
    "\n",
    "        body = \"Les rapports suivants ont été téléchargés :\\n\\n\"\n",
    "        for report in new_reports:\n",
    "            body += f\"- {report['type']} - {report.get('company', '')}\\n\"\n",
    "            body += f\"  Titre: {report['title']}\\n\"\n",
    "            body += f\"  Fichier: {report['filename']}\\n\"\n",
    "            body += f\"  URL: {report['url']}\\n\\n\"\n",
    "\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "        with smtplib.SMTP(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port']) as server:\n",
    "            server.starttls()\n",
    "            server.login(EMAIL_CONFIG['sender'], EMAIL_CONFIG['password'])\n",
    "            server.send_message(msg)\n",
    "\n",
    "        print(\"\\nEmail de notification envoyé avec succès\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErreur lors de l'envoi de l'email: {str(e)}\")\n",
    "\n",
    "def setup_download_dir():\n",
    "    os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "    if not os.path.exists(DOWNLOAD_LOG):\n",
    "        with open(DOWNLOAD_LOG, 'w') as f:\n",
    "            f.write(\"url,filename,download_date,file_size,file_hash,type,company\\n\")\n",
    "\n",
    "def create_subfolder(report_type, company):\n",
    "    clean_type = re.sub(r'[^a-zA-Z0-9]', '_', report_type)\n",
    "    subfolder_path = os.path.join(DOWNLOAD_DIR, clean_type)\n",
    "    if company:\n",
    "        clean_company = re.sub(r'[^a-zA-Z0-9]', '_', company)\n",
    "        subfolder_path = os.path.join(subfolder_path, clean_company)\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "    return subfolder_path\n",
    "\n",
    "def log_downloaded_file(pdf_info, file_path):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    file_hash = calculate_file_hash(file_path)\n",
    "    with open(DOWNLOAD_LOG, 'a') as f:\n",
    "        f.write(f\"{pdf_info['url']},{os.path.basename(file_path)},\"\n",
    "                f\"{datetime.now().isoformat()},{file_size},{file_hash},\"\n",
    "                f\"{pdf_info.get('type', 'Unknown')},{pdf_info.get('company', 'Unknown')}\\n\")\n",
    "\n",
    "def calculate_file_hash(file_path, chunk_size=8192):\n",
    "    md5 = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            md5.update(chunk)\n",
    "    return md5.hexdigest()\n",
    "\n",
    "def is_file_already_downloaded(pdf_info):\n",
    "    report_type = pdf_info.get('type', 'Unknown')\n",
    "    company = pdf_info.get('company', 'Unknown')\n",
    "    subfolder_path = os.path.join(DOWNLOAD_DIR,\n",
    "                                  re.sub(r'[^a-zA-Z0-9]', '_', report_type),\n",
    "                                  re.sub(r'[^a-zA-Z0-9]', '_', company))\n",
    "    filename = pdf_info.get('filename', os.path.basename(pdf_info['url']))\n",
    "    file_path = os.path.join(subfolder_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        return True\n",
    "    if os.path.exists(DOWNLOAD_LOG):\n",
    "        with open(DOWNLOAD_LOG, 'r') as f:\n",
    "            for line in f.readlines()[1:]:\n",
    "                if line.startswith(pdf_info['url'] + ','):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def extract_pdf_date(pdf_url, session=None):\n",
    "    try:\n",
    "        filename = unquote(os.path.basename(pdf_url))\n",
    "        \n",
    "        # Skip procurement notices\n",
    "        if \"appel_d_offre\" in filename.lower():\n",
    "            return None\n",
    "            \n",
    "        # Specific patterns for CGA reports\n",
    "        cga_patterns = [\n",
    "            r'RAP_CGA_FR_ANG_(\\d{4})',\n",
    "            r'RAPPORT_CGA_FR_ANG_(\\d{4})',\n",
    "            r'Rapport_FR-ANG_-_CGA_(\\d{4})',\n",
    "            r'rapport_annuel__FR_(\\d{4})',\n",
    "            r'Rapport_FR_(\\d{4})'\n",
    "        ]\n",
    "        \n",
    "        for pattern in cga_patterns:\n",
    "            match = re.search(pattern, filename, re.IGNORECASE)\n",
    "            if match:\n",
    "                return datetime.strptime(match.group(1), \"%Y\")\n",
    "                \n",
    "        # Extract year from title if in standard format\n",
    "        year_match = re.search(r'(20\\d{2})', filename)\n",
    "        if year_match:\n",
    "            return datetime.strptime(year_match.group(1), \"%Y\")\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Erreur d'extraction de date: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def download_pdf(pdf_info, force_redownload=False):\n",
    "    if not pdf_info or 'url' not in pdf_info:\n",
    "        print(\"  [ERROR] No PDF URL provided\")\n",
    "        return None\n",
    "        \n",
    "    # Skip if this is a procurement notice\n",
    "    if \"appel_d_offre\" in pdf_info.get('filename', '').lower():\n",
    "        print(f\"  [SKIP] Procurement notice: {pdf_info['filename']}\")\n",
    "        return None\n",
    "        \n",
    "    report_type = pdf_info.get('type', 'Autres_Rapports')\n",
    "    company = pdf_info.get('company', 'Divers')\n",
    "    subfolder_path = create_subfolder(report_type, company)\n",
    "    filename = pdf_info.get('filename', os.path.basename(pdf_info['url']))\n",
    "    save_path = os.path.join(subfolder_path, filename)\n",
    "    \n",
    "    if not force_redownload and is_file_already_downloaded(pdf_info):\n",
    "        print(f\"  [INFO] File already exists: {filename}\")\n",
    "        return None\n",
    "        \n",
    "    headers = {\n",
    "        'User-Agent': USER_AGENT,\n",
    "        'Accept': 'application/pdf',\n",
    "        'Accept-Encoding': 'identity'  # Disable compression to track progress\n",
    "    }\n",
    "    \n",
    "    current_timeout = INITIAL_TIMEOUT\n",
    "    last_exception = None\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            print(f\"\\n  [ATTEMPT {attempt + 1}/{MAX_RETRIES}] Downloading {filename}\")\n",
    "            print(f\"  URL: {pdf_info['url']}\")\n",
    "            print(f\"  Timeout: {current_timeout}s\")\n",
    "            \n",
    "            with requests.Session() as session:\n",
    "                session.headers.update(headers)\n",
    "                \n",
    "                # First, make a HEAD request to check content length\n",
    "                try:\n",
    "                    head_response = session.head(\n",
    "                        pdf_info['url'],\n",
    "                        allow_redirects=True,\n",
    "                        timeout=current_timeout\n",
    "                    )\n",
    "                    head_response.raise_for_status()\n",
    "                    \n",
    "                    content_length = head_response.headers.get('content-length')\n",
    "                    if content_length:\n",
    "                        file_size = int(content_length)\n",
    "                        if file_size > MAX_FILE_SIZE:\n",
    "                            raise ValueError(f\"File too large ({file_size/1024/1024:.2f}MB > {MAX_FILE_SIZE/1024/1024:.2f}MB)\")\n",
    "                        print(f\"  File size: {file_size/1024/1024:.2f}MB\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  [WARNING] HEAD request failed: {str(e)}\")\n",
    "                \n",
    "                # Then make the GET request with streaming\n",
    "                with session.get(\n",
    "                    pdf_info['url'],\n",
    "                    stream=True,\n",
    "                    allow_redirects=True,\n",
    "                    timeout=current_timeout\n",
    "                ) as response:\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    # Check content type\n",
    "                    content_type = response.headers.get('content-type', '')\n",
    "                    if 'pdf' not in content_type.lower():\n",
    "                        raise ValueError(f\"Unexpected content type: {content_type}\")\n",
    "                    \n",
    "                    # Start download\n",
    "                    downloaded_bytes = 0\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    with open(save_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                            if chunk:  # filter out keep-alive chunks\n",
    "                                f.write(chunk)\n",
    "                                downloaded_bytes += len(chunk)\n",
    "                                \n",
    "                                # Calculate progress\n",
    "                                elapsed = time.time() - start_time\n",
    "                                speed = downloaded_bytes / (1024 * 1024) / (elapsed + 0.0001)  # MB/s\n",
    "                                \n",
    "                                if content_length:\n",
    "                                    progress = (downloaded_bytes / file_size) * 100\n",
    "                                    print(f\"  Downloading: {progress:.1f}% | {speed:.2f} MB/s\", end='\\r')\n",
    "                    \n",
    "                    # Verify download completed\n",
    "                    if content_length and downloaded_bytes != file_size:\n",
    "                        raise IOError(f\"Incomplete download ({downloaded_bytes} of {file_size} bytes)\")\n",
    "                    \n",
    "                    print(f\"\\n  [SUCCESS] Downloaded {downloaded_bytes/1024/1024:.2f}MB in {elapsed:.1f}s ({speed:.2f} MB/s)\")\n",
    "                    \n",
    "                    # Verify file is actually a PDF\n",
    "                    with open(save_path, 'rb') as f:\n",
    "                        header = f.read(4)\n",
    "                        if header != b'%PDF':\n",
    "                            raise ValueError(\"Downloaded file is not a valid PDF\")\n",
    "                    \n",
    "                    log_downloaded_file(pdf_info, save_path)\n",
    "                    return save_path\n",
    "                    \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            last_exception = e\n",
    "            print(f\"  [ERROR] Download attempt {attempt + 1} failed: {str(e)}\")\n",
    "            \n",
    "            # Clean up partial download\n",
    "            if os.path.exists(save_path):\n",
    "                try:\n",
    "                    os.remove(save_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"  [WARNING] Could not delete partial file: {str(e)}\")\n",
    "            \n",
    "            # Exponential backoff\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                sleep_time = min(current_timeout, 60)  # Cap at 60 seconds\n",
    "                print(f\"  [INFO] Retrying in {sleep_time}s...\")\n",
    "                time.sleep(sleep_time)\n",
    "                current_timeout *= BACKOFF_FACTOR\n",
    "                \n",
    "        except Exception as e:\n",
    "            last_exception = e\n",
    "            print(f\"  [ERROR] Unexpected error: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"  [FAILED] Could not download after {MAX_RETRIES} attempts\")\n",
    "    if last_exception:\n",
    "        print(f\"  Last error: {str(last_exception)}\")\n",
    "    return None\n",
    "    \n",
    "def get_pdfs_from_page(url, keywords=None):\n",
    "    pdf_files = []\n",
    "    try:\n",
    "        print(f\"\\nAnalyse du site : {url}\")\n",
    "        headers = {'User-Agent': USER_AGENT}\n",
    "        session = requests.Session()\n",
    "        session.headers.update(headers)\n",
    "        response = session.get(url, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            link_text = link.get_text().strip()\n",
    "            \n",
    "            # Skip if not PDF or if procurement notice\n",
    "            if not href.lower().endswith('.pdf') or \"appel_d_offre\" in link_text.lower():\n",
    "                continue\n",
    "                \n",
    "            # Handle Google Drive links\n",
    "            if \"drive.google.com\" in href:\n",
    "                # Extract file ID from Google Drive URL\n",
    "                file_id_match = re.search(r'/file/d/([^/]+)', href)\n",
    "                if file_id_match:\n",
    "                    file_id = file_id_match.group(1)\n",
    "                    pdf_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                pdf_url = urljoin(url, href)\n",
    "                \n",
    "            # Extract year from title\n",
    "            year_match = re.search(r'(20\\d{2})', link_text)\n",
    "            year = year_match.group(1) if year_match else None\n",
    "            \n",
    "            # Create filename\n",
    "            if year:\n",
    "                filename = f\"Rapport_CGA_{year}.pdf\"\n",
    "            else:\n",
    "                filename = os.path.basename(pdf_url)\n",
    "                \n",
    "            pdf_files.append({\n",
    "                'url': pdf_url,\n",
    "                'date': datetime.strptime(year, \"%Y\") if year else None,\n",
    "                'filename': filename,\n",
    "                'title': link_text,\n",
    "                'context': ' '.join(link.find_parent().get_text().strip().split()[:20]),\n",
    "                'source_url': url,\n",
    "                'type': \"Rapports_CGA\",\n",
    "                'company': \"\"\n",
    "            })\n",
    "            \n",
    "        return pdf_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'accès au site {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def get_ftusa_reports(url, keywords=None):\n",
    "    try:\n",
    "        print(f\"\\nAnalyse spécifique du site FTUSA : {url}\")\n",
    "        session = requests.Session()\n",
    "        session.headers.update({'User-Agent': USER_AGENT})\n",
    "        response = session.get(url, timeout=40)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        report_links = []\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            link_text = link.get_text().strip().lower()\n",
    "            \n",
    "            if href.lower().endswith('.pdf'):\n",
    "                absolute_url = urljoin(url, href)\n",
    "                if not re.search(r'Rapport-FTUSA-20\\d{2}', absolute_url, re.IGNORECASE):\n",
    "                    continue\n",
    "                    \n",
    "                year_match = re.search(r'Rapport-FTUSA-(20\\d{2})', absolute_url, re.IGNORECASE)\n",
    "                year = year_match.group(1) if year_match else None\n",
    "                \n",
    "                if year:\n",
    "                    filename = f\"Rapport-FTUSA-{year}.pdf\"\n",
    "                    report_links.append({\n",
    "                        'url': absolute_url,\n",
    "                        'title': link_text,\n",
    "                        'date': datetime.strptime(year, \"%Y\"),\n",
    "                        'filename': filename,\n",
    "                        'context': ' '.join(link.find_parent().get_text().strip().split()[:20]),\n",
    "                        'source_url': url,\n",
    "                        'type': \"Rapports_FTUSA\",\n",
    "                        'company': \"\"\n",
    "                    })\n",
    "                    \n",
    "        return report_links\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'analyse spécifique de FTUSA: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "SITES_CONFIG = [\n",
    "    {\n",
    "        'url': \"https://www.ftusanet.org/indicateurs-du-marche-2/\",\n",
    "        'keywords': ['rapport', 'ftusa'],\n",
    "        'description': \"Rapports FTUSA sur les indicateurs de marché\",\n",
    "        'handler': get_ftusa_reports\n",
    "    },\n",
    "    {\n",
    "        'url': \"https://www.cga.gov.tn/index.php?id=96&L=0\",\n",
    "        'keywords': ['rapport', 'annuel', 'cga', 'assurance'],\n",
    "        'description': \"Rapports annuels du CGA\",\n",
    "        'retry_attempts': 3,\n",
    "        'handler': get_pdfs_from_page\n",
    "    }\n",
    "]\n",
    "\n",
    "def main():\n",
    "    setup_download_dir()\n",
    "    total_downloaded = 0\n",
    "    new_reports = []\n",
    "    \n",
    "    for config in SITES_CONFIG:\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"Recherche des PDFs: {config['description']}\")\n",
    "        print(f\"URL: {config['url']}\")\n",
    "        \n",
    "        pdfs = config['handler'](config['url'], config.get('keywords'))\n",
    "        if not pdfs:\n",
    "            print(\"  Aucun PDF correspondant trouvé.\")\n",
    "            continue\n",
    "            \n",
    "        for pdf in pdfs:\n",
    "            # Skip if no date (except for CGA reports where we extract from title)\n",
    "            if pdf['date'] is None and \"CGA\" not in pdf['type']:\n",
    "                print(f\"\\nFichier sans date détecté - ignoré:\")\n",
    "                print(f\"  URL: {pdf['url']}\")\n",
    "                print(f\"  Titre: {pdf.get('title', 'N/A')}\")\n",
    "                continue\n",
    "                \n",
    "            for attempt in range(config.get('retry_attempts', 1)):\n",
    "                print(f\"\\nTentative {attempt + 1}/{config.get('retry_attempts', 1)}\")\n",
    "                success = download_pdf(pdf)\n",
    "                if success:\n",
    "                    total_downloaded += 1\n",
    "                    new_reports.append(pdf)\n",
    "                    break\n",
    "                elif attempt < config.get('retry_attempts', 1) - 1:\n",
    "                    print(\"  Nouvelle tentative dans 5 secondes...\")\n",
    "                    time.sleep(5)\n",
    "                    \n",
    "    print(f\"\\nOpération terminée. {total_downloaded} nouveaux fichiers téléchargés avec succès.\")\n",
    "    if total_downloaded > 0:\n",
    "        send_email_notification(new_reports)\n",
    "    else:\n",
    "        print(\"\\nAucun nouveau rapport - aucun email envoyé\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21328e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
